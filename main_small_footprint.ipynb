{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small footprint proof of concept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal here is to test to what extent we can segment Ocean Parcels calculations.  In particular, can we run a long time span calculation trajectory calculation only having access to only a small subset of files at any given time.  This has two significant benefits:\n",
    "1. smaller local storage is needed as input files are rotated in and out of the Fieldset and\n",
    "2. smaller RAM is needed to store trajectory outputs since particle positions are written out incrementally.\n",
    "\n",
    "Below, we run two cases:\n",
    "1. Reference case (**ref**): OceanParcels has access to everything and runs all trajectories all at once,\n",
    "2. Incremental file read and incremental data write (**irw**): OceanParcels only can see the files it needs for each step and spits out trajectories incrementally.\n",
    "\n",
    "It seems that OceanParcels *by default* incrementally writes output to the out-XXXXX/NNN.npy files. However, it seems to be appending subsets of the particles to each file and also creating new files as time progresses.  Fewer files are created for shorter duration runs but for the long runs, the time stamps are all up to current time suggesting that even though files are created incrementally, nearly all files are still written to over the course of the run.  It may be that older files are only being appended linking information (which files their data spills over to) in an effort to keep all files about the same size. The [OceanParcels output tutorial](https://nbviewer.jupyter.org/github/OceanParcels/parcels/blob/master/parcels/examples/tutorial_output.ipynb) does not elaborate on this point so will need to search elsewhere for the specifics on this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n",
    "We start with importing the relevant modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Compiled ParcelsRandom ==> /tmp/parcels-40545/libparcels_random_853766cb-21a1-4487-a19a-704c6c56e3c8.so\n"
     ]
    }
   ],
   "source": [
    "from parcels import FieldSet, ParticleSet, JITParticle, AdvectionRK4, ErrorCode\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import os\n",
    "import netCDF4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Reference case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input velocity fields for reference case\n",
    "\n",
    "We will use the Globcurrent fields from the `GlobCurrent_example_data` directory leveraging the fact that all filenames are nearly the same format with `<YYYY><MM><DD><HH><MM><SS>-GLOBCURRENT...`.  In this case, it is pretty simple because all files represent 1 day at the same time each day (uniform time increment).  Right here, note that OceanParcels has access to all files for this baseline case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Casting lon data to np.float32\n",
      "WARNING: Casting lat data to np.float32\n",
      "WARNING: Casting depth data to np.float32\n"
     ]
    }
   ],
   "source": [
    "filenames = \"/pw/workflows/ocean_parcels_demo/parcels_examples/GlobCurrent_example_data/20*.nc\"\n",
    "variables = {'U': 'eastward_eulerian_current_velocity',\n",
    "             'V': 'northward_eulerian_current_velocity'}\n",
    "dimensions = {'lat': 'lat',\n",
    "              'lon': 'lon',\n",
    "              'time': 'time'}\n",
    "fieldset = FieldSet.from_netcdf(filenames, variables, dimensions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize particle set\n",
    "\n",
    "Now create vectors of Longitude and Latitude starting locations on a regular mesh, and use these to initialise a `ParticleSet` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lons, lats = np.meshgrid(range(15, 35), range(-40, -30))\n",
    "pset = ParticleSet(fieldset=fieldset, pclass=JITParticle, lon=lons, lat=lats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output file for reference case\n",
    "\n",
    "Specify the file name and output time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_out_file = pset.ParticleFile(name=\"ref.nc\", outputdt=timedelta(hours=24))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to advect the particles. However, the Globcurrent data that we loaded in is only for a limited, regional domain and particles might be able to leave this domain. We therefore need to tell Parcels that particles that leave the domain need to be deleted. We do that using a `Recovery Kernel`, which will be invoked when a particle encounters an `ErrorOutOfBounds` error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DeleteParticle(particle, fieldset, time):\n",
    "    particle.delete()\n",
    "    \n",
    "def StopParticle(particle, fieldset, time):\n",
    "    particle.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advect particles for reference case\n",
    "\n",
    "Now we can advect the particles. Note that we do this inside a `for`-loop, so we can save a plot every six hours (which is the value of `runtime`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Compiled JITParticleAdvectionRK4 ==> /tmp/parcels-40545/de0b640c8f8860e4f12fe3862faa8356_0.so\n",
      "WARNING: Casting field data to np.float32\n"
     ]
    }
   ],
   "source": [
    "# Inputs: pset, DeleteParticle\n",
    "# Outputs: list of files (each file name is in savefile)\n",
    "#for cnt in range(10):\n",
    "    # Set filename for output plot\n",
    "    #output_image = 'particles'+str(cnt).zfill(2)\n",
    "    #print(output_image)\n",
    "    \n",
    "    # First plot the particles\n",
    "    #pset.show(savefile=output_image, field='vector', land=True, vmax=2.0)\n",
    "\n",
    "    # Then advect the particles for 24 hours (to match file increment)\n",
    "#    pset.execute(AdvectionRK4,\n",
    "#                 runtime=timedelta(hours=24),  # runtime controls the interval of the plots\n",
    "#                 dt=timedelta(minutes=5),\n",
    "#                 output_file=ref_out_file,\n",
    "#                 recovery={ErrorCode.ErrorOutOfBounds: DeleteParticle})  # the recovery kernel\n",
    "    \n",
    "pset.execute(AdvectionRK4,\n",
    "    runtime=timedelta(days=10),  # runtime controls the interval of the plots\n",
    "    dt=timedelta(minutes=5),\n",
    "    output_file=ref_out_file,\n",
    "    recovery={ErrorCode.ErrorOutOfBounds: DeleteParticle})  # the recovery kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write output file for reference case\n",
    "Running this again will overwrite any existing .nc file with the same name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ref_out_file.close()  # Will destroy the *.npy source files after coalescing\n",
    "ref_out_file.export()  # Will coalesce the *.npy source files and keep them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Incremental data access\n",
    "\n",
    "Now we copy over files to the current working directory to ensure only subsets of files are \"available\" at a given time.  This simulates the process of sending files just in time to the worker, thus allowing for a smaller worker footprint and potentially running data transfer at the same time as the calculation.\n",
    "\n",
    "At its core, OceanParcels uses `np.save('file.npy',var)` in `parcels.particlefile.baseparticlefile` to save variables which will preserve the precision stored in memory.  This has the potential to reduce chaotic effects of small offsets between trajectories allowing for the same trajectories to be computed incrementally as they are computed all in one go.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input velocity fields for the incremental read case\n",
    "The `variables` and `dimensions` field specifications set above do not need to change.  Reset `filenames` to match the current working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = \"20*.nc\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incremental loop\n",
    "For each iteration of the loop, we need to repeat the separate steps executed above:\n",
    "1. Copy over relevant files\n",
    "2. Initialize the FieldSet\n",
    "3. Initialize the ParticleSet\n",
    "4. Initialize the incremental file\n",
    "5. Advect the ParticleSet\n",
    "6. Save the incremental file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "Working on files: \n",
      "/pw/workflows/ocean_parcels_demo/parcels_examples/GlobCurrent_example_data/20020101000000-GLOBCURRENT-L4-CUReul_hs-ALT_SUM-v02.0-fv01.0.nc\n",
      "/pw/workflows/ocean_parcels_demo/parcels_examples/GlobCurrent_example_data/20020102000000-GLOBCURRENT-L4-CUReul_hs-ALT_SUM-v02.0-fv01.0.nc\n"
     ]
    }
   ],
   "source": [
    "# Inputs: pset, DeleteParticle\n",
    "# Outputs: list of files (each file name is in savefile)\n",
    "for cnt in range(10):\n",
    "    # Set infile files\n",
    "    basename = \"/pw/workflows/ocean_parcels_demo/parcels_examples/GlobCurrent_example_data/200201\"\n",
    "    endname = \"000000-GLOBCURRENT-L4-CUReul_hs-ALT_SUM-v02.0-fv01.0.nc\"\n",
    "    infile1 = basename+str(cnt+1).zfill(2)+endname\n",
    "    infile2 = basename+str(cnt+2).zfill(2)+endname\n",
    "    print(\"-------------------------------\")\n",
    "    print(\"Working on files: \")\n",
    "    print(infile1)\n",
    "    print(infile2)\n",
    "    \n",
    "    # Copy the two files in this working directory so we can make a particle set\n",
    "    err = os.system(\"cp \"+infile1+\" ./\")\n",
    "    err = os.system(\"cp \"+infile2+\" ./\")\n",
    "\n",
    "    # Initialize the FieldSet\n",
    "    fieldset = FieldSet.from_netcdf(filenames, variables, dimensions)\n",
    "    \n",
    "    # Initialize the ParticleSet\n",
    "    # Note launch locations are initialized above and will be\n",
    "    # updated with end of this run based on outputs created here.\n",
    "    pset = ParticleSet(fieldset=fieldset, pclass=JITParticle, lon=lons, lat=lats)\n",
    "    \n",
    "    # Initialize the output file\n",
    "    irw_out_file_name = \"irw\"+str(cnt+1).zfill(2)+\".nc\"\n",
    "    irw_out_file = pset.ParticleFile(name=irw_out_file_name, outputdt=timedelta(hours=24))\n",
    "    \n",
    "    # Advect the particles for 24 hours\n",
    "    pset.execute(AdvectionRK4,\n",
    "                 runtime=timedelta(hours=24),  # runtime controls the interval of the plots\n",
    "                 dt=timedelta(minutes=5),\n",
    "                 output_file=irw_out_file,\n",
    "                 recovery={ErrorCode.ErrorOutOfBounds: DeleteParticle})  # the recovery kernel\n",
    "    \n",
    "    # Coalesce data\n",
    "    irw_out_file.export()\n",
    "    \n",
    "    # Update lons and lats by loading final\n",
    "    # points from the output file.\n",
    "    irw_out_data = netCDF4.Dataset(irw_out_file_name)\n",
    "    ids = irw_out_data.variables[\"trajectory\"][:][:,0]\n",
    "    lons = irw_out_data.variables[\"lon\"][:][:,-1]\n",
    "    lats = irw_out_data.variables[\"lat\"][:][:,-1]\n",
    "    \n",
    "    # Clean up by removing current files (can do this more \n",
    "    # intelligently by moving only one file at a time, etc.)\n",
    "    err = os.system(\"rm -f 20*.nc\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and plot reference data\n",
    "ref_out_data = netCDF4.Dataset(\"ref.nc\")\n",
    "ref_lons = ref_out_data.variables[\"lon\"][:]\n",
    "ref_lats = ref_out_data.variables[\"lat\"][:]\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=[20,10])\n",
    "ax.plot(ref_lons,ref_lats,'bo')\n",
    "\n",
    "# Load and plot incremental read/write data\n",
    "for cnt in range(10):\n",
    "    irw_out_file_name = \"irw\"+str(cnt+1).zfill(2)+\".nc\"\n",
    "    irw_out_data = netCDF4.Dataset(irw_out_file_name)\n",
    "    ids = irw_out_data.variables[\"trajectory\"][:][:,0]\n",
    "    lons = irw_out_data.variables[\"lon\"][:]\n",
    "    lats = irw_out_data.variables[\"lat\"][:]\n",
    "    ax.plot(lons,lats,'r+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=[10,10])\n",
    "ax.plot(ref_lons[:,-1],lons[:,-1])\n",
    "ax.plot(ref_lats[:,-1],lats[:,-1])\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ref_lons[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cnt in range(10):\n",
    "    irw_out_file_name = \"irw\"+str(cnt+1).zfill(2)+\".nc\"\n",
    "    irw_out_data = netCDF4.Dataset(irw_out_file_name)\n",
    "    ids = irw_out_data.variables[\"trajectory\"][:][:,0]\n",
    "    lons = irw_out_data.variables[\"lon\"][:]\n",
    "    lats = irw_out_data.variables[\"lat\"][:]\n",
    "    print(lons[1,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Resources\n",
    "\n",
    "1. [Overall structure](https://github.com/OceanParcels/parcels/blob/master/parcels/examples/tutorial_parcels_structure.ipynb)\n",
    "2. [Timestamps on fields](https://nbviewer.jupyter.org/github/OceanParcels/parcels/blob/master/parcels/examples/tutorial_timestamps.ipynb)\n",
    "3. [Delayed starts](https://github.com/OceanParcels/parcels/blob/master/parcels/examples/tutorial_delaystart.ipynb)\n",
    "4. [JIT vs SciPy particles](https://github.com/OceanParcels/parcels/blob/master/parcels/examples/tutorial_jit_vs_scipy.ipynb)\n",
    "5. [Parallel OceanParcels](https://github.com/OceanParcels/parcels/blob/master/parcels/examples/documentation_MPI.ipynb)\n",
    "6. [Main documentation](https://oceanparcels.org/gh-pages/html/)\n",
    "7. [Plotting/Analysis examples](https://nbviewer.jupyter.org/github/OceanParcels/parcels/blob/master/parcels/examples/tutorial_output.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
